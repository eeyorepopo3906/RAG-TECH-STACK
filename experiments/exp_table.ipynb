{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "\n",
    "#from src.local_models.llm import MyLLM, LlamaCPPLLM\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from local_models.embeddings import get_embed_model\n",
    "\n",
    "from data_loader.splitting import split_by_md_headers\n",
    "from data_loader.parsing import get_html, extract_md_tables\n",
    "\n",
    "from llama_index.core import Document\n",
    "from data_loader.chunking import chunk_docs_standalone\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "from data_loader.load_from_dir import rebuild_index\n",
    "from utils import load_prompt\n",
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.agent.openai import OpenAIAgent\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = get_embed_model(model_name=os.environ['embed_path'],  model_kwargs={'device': 'cpu'}, encode_kwargs = {'normalize_embeddings': True})\n",
    "#llm = MyLLM(pretrained_model_name_or_path=os.environ['llm_path'], device_map=\"mps\", context_window=4096, num_output=512, model_name='chatglm3-6b')\n",
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first-time build\n",
    "\"\"\"\n",
    "df = split_by_md_headers('data/产品白皮书/KDP-WhitePaper.md')\n",
    "df['text_html'] = df['content'].apply(lambda x: get_html(x))\n",
    "df = extract_md_tables(df)\n",
    "\n",
    "table_docs = [Document(text=tbl, metadata={}) for tbl in df[df['is_table']==1]['table'].values]\n",
    "\n",
    "text_docs = [Document(text=tbl, metadata={}) for tbl in df[df['is_table']==0]['text'].values]\n",
    "text_nodes = [chunk_docs_standalone(text_docs[i], chunk_size=512, chunk_overlap=50)[0] for i in range(len(text_docs))]\n",
    "\n",
    "table_index = VectorStoreIndex.from_documents(table_docs)\n",
    "text_index = VectorStoreIndex(text_nodes)\n",
    "\n",
    "#persist to disk\n",
    "#table_index.storage_context.persist(persist_dir=\"db_stores/table_index\")\n",
    "#text_index.storage_context.persist(persist_dir='db_stores/text_index')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load prompt\n",
    "prompt_str = load_prompt('prompt_bank/whitepaper.txt')\n",
    "new_vector_tmpl = PromptTemplate(prompt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rebuild storage context from disk\n",
    "table_index = rebuild_index(\"db_stores/table_index\")\n",
    "text_index = rebuild_index(\"db_stores/text_index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_engine = table_index.as_query_engine()\n",
    "text_engine = text_index.as_query_engine()\n",
    "\n",
    "text_engine.update_prompts({'response_synthesizer:text_qa_template': new_vector_tmpl})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tools\n",
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=table_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"table_tool\",\n",
    "            description=(\n",
    "                \"Useful for retriving specific context from tables\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    QueryEngineTool(\n",
    "        query_engine=text_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"text_tool\",\n",
    "            description=(\n",
    "                \"Useful for retriving specific context from plain text\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build agent\n",
    "agent = OpenAIAgent.from_tools(\n",
    "    query_engine_tools,\n",
    "    max_function_calls=3,\n",
    "    verbose=True,\n",
    "    system_prompt=f\"\"\"\\\n",
    "        Respond in Chinese.\n",
    "        \n",
    "        If you inquire general-purpose questions, refer to the text_tool as a priority.\n",
    "        For questions involving numbers and figures, refer to the table_tool first.\n",
    "        If you need to analyze tech-savvy problems, which demands a higher degree of rigorous reasoning, such as step-by-step instructions, \n",
    "        please utilize both the text_tool and table_tool to synthesize your answer.\n",
    "        \n",
    "        You must ALWAYS use at least one of the tools provided when answering a question; do NOT rely on prior knowledge.\\\n",
    "        \"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: 云原生相比传统大数据平台的优势在哪里\n",
      "=== Calling Function ===\n",
      "Calling function: text_tool with args: {\"input\":\"云原生相比传统大数据平台的优势在哪里\"}\n",
      "Got output: 云原生相比传统大数据平台的优势在于可以显著提升运维效率，降低运维成本，解放技术团队的生产力。传统大数据平台因为技术扩展迭代流程比较慢，不能及时解决运维中碰到的性能瓶颈，而云原生技术以容器和Kubernetes为代表，能够更快速地部署、升级和管理大数据组件，提高运维效率，降低成本，让技术团队更专注于业务开发和数据价值的发现。\n",
      "========================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response(response='云原生相比传统大数据平台的优势在于可以显著提升运维效率，降低运维成本，解放技术团队的生产力。传统大数据平台因为技术扩展迭代流程比较慢，不能及时解决运维中碰到的性能瓶颈，而云原生技术以容器和Kubernetes为代表，能够更快速地部署、升级和管理大数据组件，提高运维效率，降低成本，让技术团队更专注于业务开发和数据价值的发现。', source_nodes=[NodeWithScore(node=TextNode(id_='f0d61784-64ac-4a78-bc5f-dc7e720816c0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='998da1a2-2895-4db2-827a-a6e40f06f238', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='a12c19a5dceb79caf9e922981d7145ee5f65f945205c0db59a6c08b70bb0428b')}, text='传统大数据平台因为技术扩展迭代流程比较慢，不能及时解决运维中碰到的性能瓶颈，同时大数据组件之间软件包依赖很复杂，导致组件升级困难，新的组件集成耗时费力。使用传统大数据平台的技术团队面对运维压力疲于奔命，没有精力专注于业务开发和数据价值的发现。传统大数据平台逐步迁移到云原生大数据平台后，可以显著提升运维效率，降低运维成本，解放技术团队的生产力\\n。', start_char_idx=0, end_char_idx=173, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.884591022601091), NodeWithScore(node=TextNode(id_='bfa90f68-f75d-4afa-ab5b-184876908f15', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='6cad3984-68fd-4067-99f5-5e912c8d713e', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='2d8e617d6c1fb6c1a4f9a557acd3211daa109bbac6e6f77fec5a8edf8a891983'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2a632c24-2ed8-4eb3-a28b-48c10e366431', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='48e2239ad96f8a811f9b866240626fe02afad0c6c53c20fb27e77cadc0695026')}, text='既然不能够依靠Hadoop生态技术本身的发展来解决传统大数据平台带来的难题，那么我们就应该把注意力放到  \\n\\n当前最新的技术发展趋势之上，也就是以容器和K8s为代表的云原生技术。云原生技术在2013年容器项目以及2014年K8s项目正式发布以后，发展非常迅猛。现在，各大公有云厂商都支持K8s，还有上百家技术公司在持续投入K8s的迭代和更新工作。成立于2015年的云原生计算基金会（CNCF），将K8s作为其托管的第一个项目。截止2022年五月，该基金会已经托管了123个项目，近200个国家的16万开发者在为这些项目开发代码。更令人兴奋的是，CNCF的生态全景图目前包含了1000多个云原生技术产品，覆盖了数据库、消息级流处理、调度和任务编排、存储系统等10多个技术领域。  \\n\\n2021年应该是云原生大数据技术发展的里程碑，在这一年，有两个重大的技术进展被公布。一个是2021年3月，Apache 宣布 Spark 3.1 正式支持了 K8s， 另外在2021年5月， Apache Kafka 背后的商业公司 Confluent 也发布了Confluent on K8s，一个能私有发布的在K8s之上运行的Kafka生产集群系统。这两个重要事件表明，大数据平台的云原生化已是大势所趋。', start_char_idx=0, end_char_idx=545, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8531587480090775)], metadata=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.query('云原生相比传统大数据平台的优势在哪里')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: kdp中hdfs的读写速度是多少\n",
      "=== Calling Function ===\n",
      "Calling function: text_tool with args: {\"input\":\"kdp中hdfs的读写速度是多少\"}\n",
      "Got output: 根据文档内容无法回答该问题。\n",
      "========================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response(response='根据文档内容，无法提供KDP中HDFS的读写速度信息。您可以参考KDP的官方文档或者性能测试报告来获取更详细的信息。', source_nodes=[NodeWithScore(node=TextNode(id_='b6e9eb80-3f22-4c29-894c-bffb18430510', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='eb8568f6-892c-4754-9d72-9f02d15668a3', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='4a6774007d6df8dd5542598a2f3968b644292796b3dafc020580e68041dcdc16'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8acbd7f9-ef6e-47a5-abd9-9e14fa50fbcb', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8f3e1b8362d5fb13b0383deea72263fbb9a060944eb70bffa795fda498b3991b')}, text='分布式文件系统HDFS是一个可以运行在普通硬件上的文件系统，它通过将文件分块保存到不同的节点并且每个块保存多个副本的方式来实现高容错性。HDFS存的每个数据块有3个备份，分布在不同的数据节点上，来实现高可用。KDP通过对开源的helm chart进行扩展将HDFS的非云原生特性进行了改造：  \\n\\n- 原来的基于本地硬盘的存储改造成了基于PV的云原生存储模式。\\n- 将host网络改造成了pod的虚拟网络。\\n- 实现了datanode的（在硬件环境支持的情况下）弹性扩容。  \\n\\n原本基于本地硬盘的存储方式被KDP改造成了基于PV的云原生存储模式。这一改进提高了数据的可靠性和可扩展性，使HDFS更适应云环境的动态特性。其次，将原有的基于host网络的通信模式转变为pod的虚拟网络。这种改造增强了网络的隔离性，使得HDFS更好地适应容器化环境，提高了整体的可管理性和灵活性。在实现高可用方面，引入了基于Zookeeper的高可用部署模式。这个改进确保了HDFS在面临节点故障时能够保持高可用性，为用户提供了更加可靠的服务。安全方面，通过集成Kerberos安全认证和Apache Ranger授权机制，KDP实现了更加严密的安全层。这为敏感数据的保护提供了可靠的手段，增强了HDFS在企业环境中的可信度。', start_char_idx=0, end_char_idx=553, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8209141191568836), NodeWithScore(node=TextNode(id_='d3ff851c-9508-494d-b5fd-d20480f5d20b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='b97a9647-62bb-4753-a764-cbda6d0f2c8d', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='849f23d2f2aaac147bdb7eca0f7fba4703e30f7e4a4fb5c78b3864f8922aef08')}, text='对于存储引擎背后的物理存储，KDP是通过声明PVC，以PV的方式来实现的。由于HDFS、MinIO和Kafka本身的存储架构已经实现了数据存储的高可用，那就没必要在物理存储层再做高可用的实现，所以KDP采用openEBS的Local PV来做这些存储引擎和Kafka的物理存储， 当少数节点或者PV出现故障的时候， 并不会影响这些存储引擎和Kafka的可用性。我们的性能测试指标显示，这种Local PV的存储方案相比直接磁盘访问，并没有显著的性能差异\\n。', start_char_idx=0, end_char_idx=228, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8180145209656585)], metadata=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.query('kdp中hdfs的读写速度是多少')\n",
    "#agent.chat('kdp中hdfs的读写速度如何')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: kdp中hdfs的版本是多少\n",
      "=== Calling Function ===\n",
      "Calling function: table_tool with args: {\"input\":\"KDP中HDFS的版本\"}\n",
      "Got output: 3.1.1\n",
      "========================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response(response='KDP中HDFS的版本是3.1.1。', source_nodes=[NodeWithScore(node=TextNode(id_='9d947b6a-267a-4d13-9223-bb79fb6fe7d4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='ddf132db-f2a5-431c-b29d-1042fc039c6d', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='54daf0932ee691d230bf064828f0ca9ab462a83f3c15001d3b9e724801cab10b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9160c668-2300-4e82-90f5-5a0e31e8544e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4a06b8f7474c879971bf5d03f0e86676eb279c84ff8fe94b96489361f7e28915')}, text='| 大数据组件 | 版本 |\\n| --- | --- |\\n| 分布式文件系统HDFS | 3.1.1 |\\n| 分布式数据仓库Hive | 3.1.3 |\\n| 分布式计算引擎Spark | 3.3.0 |\\n| 分布式消息队列Kafka | 2.8.1 |\\n| 分布式对象存储MinIO | RELEASE.2022-09-07 |\\n| 批流一体计算引擎Flink | 1.14.6 |', start_char_idx=2, end_char_idx=193, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8496439328650923), NodeWithScore(node=TextNode(id_='9160c668-2300-4e82-90f5-5a0e31e8544e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='ef02f36d-5a00-4493-b3cd-cccf58250599', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='53b2b294f83f563d2a8564030bdcbc7fadf31823e8439b7bf39a56e739c7c90f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9d947b6a-267a-4d13-9223-bb79fb6fe7d4', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='84c4e4a7a49a4ba5cb0e348933042aa350fd2a36d5bdafadbc4d585a35cb40bb')}, text='| 测试文件大小：17GB | 传统HDFS集群 | K8s HDFS集群 |\\n| --- | --- | --- |\\n| 读（平均值） | 313.12MB/s | 305.46MB/s |\\n| 写（平均值） | 85.13MB/s | 82.76MB/s |', start_char_idx=2, end_char_idx=133, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8229065339882663)], metadata=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.query('kdp中hdfs的版本是多少')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
